{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[DACON_news]BERT.ipynb","provenance":[],"collapsed_sections":["PALrcfSmiSLY"],"authorship_tag":"ABX9TyO0xwwThm2xjfbzHUajaKn1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0231af189014405697587319e56f7ef3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5305a95715c842d8b9ae6e86537a96dd","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f94d1d76b8e64f748ee30be815517d3e","IPY_MODEL_3ab0ae8bcd2046e1bfbe3413d571ecb7"]}},"5305a95715c842d8b9ae6e86537a96dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f94d1d76b8e64f748ee30be815517d3e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d7962aa08fc043b789f27e0d878c4ed7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_32e8f47817d24ab8b189260e92870081"}},"3ab0ae8bcd2046e1bfbe3413d571ecb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_409a0c3ad75345a992ae170121dc7e88","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:00&lt;00:00, 7.62kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_06d7c317c647427893084c8108da30f6"}},"d7962aa08fc043b789f27e0d878c4ed7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"32e8f47817d24ab8b189260e92870081":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"409a0c3ad75345a992ae170121dc7e88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"06d7c317c647427893084c8108da30f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78c361e1139042f8bc0d1726c5c35b92":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bc97e8299d6941b79952ebfdeb0f0566","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_83e9d85a3155496392f57c7ab4ff1616","IPY_MODEL_3bdc7d31815c4e10b8d23017c94f0522"]}},"bc97e8299d6941b79952ebfdeb0f0566":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83e9d85a3155496392f57c7ab4ff1616":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_372048e528244c13bf8ef0cae02c1e02","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":714314041,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":714314041,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e7b0b60077844f27b741844587f7ca2f"}},"3bdc7d31815c4e10b8d23017c94f0522":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4ddf56d982354e029b1ee428676e541b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 714M/714M [00:17&lt;00:00, 40.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b8e9c22b57d344c1af5b52a6ceaec811"}},"372048e528244c13bf8ef0cae02c1e02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e7b0b60077844f27b741844587f7ca2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4ddf56d982354e029b1ee428676e541b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b8e9c22b57d344c1af5b52a6ceaec811":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":784},"id":"GZSjjcotJpwj","executionInfo":{"status":"ok","timestamp":1627633169859,"user_tz":-540,"elapsed":25217,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"05953005-4ad0-4a95-9255-2c044a1483f1"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from nltk import FreqDist\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.sequence import pad_sequences\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","from tqdm import tqdm\n","import math\n","!pip install transformers\n","from transformers import BertTokenizer, BertForSequenceClassification\n","from transformers import get_linear_schedule_with_warmup"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.9.1-py3-none-any.whl (2.6 MB)\n","\u001b[K     |████████████████████████████████| 2.6 MB 3.9 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 35.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 35.2 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 29.4 MB/s \n","\u001b[?25hCollecting huggingface-hub==0.0.12\n","  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["yaml"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CQJdr8ko2Pty","executionInfo":{"status":"ok","timestamp":1626954712708,"user_tz":-540,"elapsed":953,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"20e6c408-8fa0-4742-8ccb-ba852492727e"},"source":[" ! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'Mecab-ko-for-Google-Colab'...\n","remote: Enumerating objects: 91, done.\u001b[K\n","remote: Counting objects: 100% (91/91), done.\u001b[K\n","remote: Compressing objects: 100% (85/85), done.\u001b[K\n","remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n","Unpacking objects: 100% (91/91), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AzVOx96G2Tia","executionInfo":{"status":"ok","timestamp":1626954712708,"user_tz":-540,"elapsed":8,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"83a1ad6c-59d0-4328-fde5-9e8434bfbcf7"},"source":[" cd Mecab-ko-for-Google-Colab"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/Mecab-ko-for-Google-Colab\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSTP4m592d_f","executionInfo":{"status":"ok","timestamp":1626955127815,"user_tz":-540,"elapsed":70301,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"75c9f85e-378c-4a51-e17a-f11d469e4f45"},"source":[" ! bash install_mecab-ko_on_colab190912.sh"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Installing konlpy.....\n","Collecting konlpy\n","  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |████████████████████████████████| 19.4 MB 121 kB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 46.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Collecting beautifulsoup4==4.6.0\n","  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 5.6 MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n","Done\n","Installing mecab-0.996-ko-0.9.2.tar.gz.....\n","Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n","from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n","--2021-07-22 11:51:58--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n","Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c3:9b0a, 2406:da00:ff00::22c2:513, ...\n","Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=Mvrp6u9GmaqrcalPWhqV6zbJXXA%3D&Expires=1626955801&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n","--2021-07-22 11:51:58--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=Mvrp6u9GmaqrcalPWhqV6zbJXXA%3D&Expires=1626955801&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n","Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.244.28\n","Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.244.28|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1414979 (1.3M) [application/x-tar]\n","Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n","\n","mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.05s   \n","\n","2021-07-22 11:51:58 (25.1 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n","\n","Done\n","Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n","Done\n","Change Directory to mecab-0.996-ko-0.9.2.......\n","installing mecab-0.996-ko-0.9.2.tar.gz........\n","configure\n","make\n","make check\n","make install\n","ldconfig\n","Done\n","Change Directory to /content\n","Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n","from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n","--2021-07-22 11:53:28--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n","Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c2:513, 2406:da00:ff00::22c3:9b0a, ...\n","Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=3V9L7hN0rd8RlmXG0Ok6LGsRuw0%3D&Expires=1626956187&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n","--2021-07-22 11:53:28--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=3V9L7hN0rd8RlmXG0Ok6LGsRuw0%3D&Expires=1626956187&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n","Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.204.139\n","Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.204.139|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 49775061 (47M) [application/x-tar]\n","Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n","\n","mecab-ko-dic-2.1.1- 100%[===================>]  47.47M   106MB/s    in 0.4s    \n","\n","2021-07-22 11:53:28 (106 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n","\n","Done\n","Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n","Done\n","Change Directory to mecab-ko-dic-2.1.1-20180720\n","Done\n","installing........\n","configure\n","make\n","make install\n","apt-get update\n","apt-get upgrade\n","apt install curl\n","apt install git\n","bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n","Done\n","Successfully Installed\n","Now you can use Mecab\n","from konlpy.tag import Mecab\n","mecab = Mecab()\n","사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n","NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n","블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SHtDoDk22oud"},"source":["from konlpy.tag import Mecab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r55uqQWNLLBY"},"source":["SEED = 2021\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rQl2qs3XLk6Q","executionInfo":{"status":"ok","timestamp":1626955226621,"user_tz":-540,"elapsed":65890,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"4272efda-a149-46a8-fe0a-95b969d63d74"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RUcGKALwL4cl"},"source":["PATH = '/content/drive/MyDrive/DL/DACON-news/'\n","train = pd.read_csv(PATH+'train_data.csv').iloc[:,1:]\n","test = pd.read_csv(PATH+'test_data.csv').iloc[:,1:]\n","submission = pd.read_csv(PATH+'sample_submission.csv')\n","topic_dict = pd.read_csv(PATH+'topic_dict.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"udekQ_D9O9FW"},"source":["# 전처리"]},{"cell_type":"code","metadata":{"id":"yjdN-y6b3RWv"},"source":["sentences = train['title']\n","#sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","labels = train['topic_idx'].values\n","\n","tokenizer = Mecab()\n","tokenized_texts = [tokenizer.morphs(t) for t in sentences]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1IuGrrg9S1T","executionInfo":{"status":"ok","timestamp":1626955331676,"user_tz":-540,"elapsed":1251,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"e5e46012-5a2a-4290-f136-c53ced5b2122"},"source":["## vocab만들기\n","\n","\n","vocab = FreqDist(np.hstack(tokenized_texts))\n","print('전체 단어 수:', len(vocab))\n","vocab = dict(filter(lambda x: x[1]>=3,vocab.items()))\n","#vocab = vocab.most_common()\n","print('전체 vocab 수:', len(vocab))\n","\n","#word_to_index = {word[0] : index + 1 for index, word in enumerate(vocab)}\n","word_to_index = dict()\n","word_to_index['[CLS]'] = 101\n","word_to_index['[SEP]'] = 102\n","\n","for t in tokenized_texts:\n","    t.insert(0,'[CLS]')\n","    t.insert(len(t),'[SEP]')\n","\n","index = 1\n","for word in vocab:\n","    if index==101:\n","        index = 103\n","    word_to_index[word] = index\n","    index+=1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["전체 단어 수: 30903\n","전체 vocab 수: 14603\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3fgafaLV76JE","executionInfo":{"status":"ok","timestamp":1626955335546,"user_tz":-540,"elapsed":315,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"02c071a5-0c78-4abc-d6bb-6037b5e11657"},"source":["max_token_num = pd.Series([len(t) for t in tokenized_texts]).max()\n","max_token_num"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["26"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"XJvOSoL39PKv"},"source":["## encoding\n","input_ids = []\n","for sent in tokenized_texts:\n","    sent_ids = []\n","    for token in sent:\n","        try:\n","            sent_ids.append(word_to_index[token])\n","        except:\n","            sent_ids.append(0)\n","    input_ids.append(sent_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EcuGiv07NyJ-"},"source":["순서를 고려한 정수 encoding"]},{"cell_type":"code","metadata":{"id":"GGWh3bwh72mt"},"source":["## padding\n","MAX_LEN = max_token_num\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","## masking\n","attention_masks = []\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezNHHkbGEe7D"},"source":["train_inputs = torch.tensor(input_ids)\n","train_labels = torch.tensor(labels)\n","train_masks = torch.tensor(attention_masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1fu_zqZOG4zP"},"source":["# 배치 사이즈\n","batch_size = 32\n","\n","# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","# 학습시 배치 사이즈 만큼 데이터를 가져옴\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GeIHqw24KqPw"},"source":["test data 전처리"]},{"cell_type":"code","metadata":{"id":"_4JPBdorKtrf"},"source":["sentences = test['title']\n","#sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","\n","tokenizer = Mecab()\n","tokenized_texts = [tokenizer.morphs(t) for t in sentences]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GzwPU_d2K8hA"},"source":["## encoding\n","input_ids = []\n","for sent in tokenized_texts:\n","    sent_ids = []\n","    for token in sent:\n","        try:\n","            sent_ids.append(word_to_index[token])\n","        except:\n","            sent_ids.append(0)\n","    input_ids.append(sent_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cjwlealhLBHF"},"source":["## padding\n","MAX_LEN = max_token_num\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","## masking\n","attention_masks = []\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"77093EfFLD_D"},"source":["test_inputs = torch.tensor(input_ids)\n","test_masks = torch.tensor(attention_masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6bSepCo4HwQA"},"source":["batch_size = 32\n","\n","test_data = TensorDataset(test_inputs, test_masks)\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PALrcfSmiSLY"},"source":["# 전처리 (pre)"]},{"cell_type":"code","metadata":{"id":"8-E2ao80OwkX"},"source":["train.to_csv(PATH+'train.csv', index=False)\n","test.to_csv(PATH+'test.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"id":"NCv6qiM7VkXL","executionInfo":{"status":"ok","timestamp":1626682231602,"user_tz":-540,"elapsed":61378,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"8a4b4597-3afb-47c1-f4ab-4e1e2952dfe8"},"source":["data = pd.read_csv(PATH+'text.txt', header=None)\n","data['tokenized_len'] = [len(tokenizer.morphs(t)) for t in data[0]]\n","data.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tokenized_len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>54785.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>10.964844</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>2.573774</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>9.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>11.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>13.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>22.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       tokenized_len\n","count   54785.000000\n","mean       10.964844\n","std         2.573774\n","min         1.000000\n","25%         9.000000\n","50%        11.000000\n","75%        13.000000\n","max        22.000000"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"rpJg0i1FMoXT"},"source":["def tokenize_ko(text):\n","    return [i for i in tokenizer.morphs(text)]\n","\n","text = Field(tokenize=tokenize_ko, sequential=True, use_vocab=True, lower=True, batch_first=True, fix_length=22)\n","label = Field(sequential=False, use_vocab=False, is_target=True)\n","data_fields = [('text',text), ('label',label)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pIVrS7LUOfKu"},"source":["train, test = TabularDataset.splits(path=PATH, train='train.csv', test='test.csv',  \n","                                    format='csv', skip_header=True, fields=data_fields)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GoiOTDesUFuP","executionInfo":{"status":"ok","timestamp":1626682284498,"user_tz":-540,"elapsed":35,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"0f1a58fb-d4f0-4074-87a5-ca702121fb89"},"source":["print(vars(train[1]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'text': ['실리콘밸리', '넘어서겠다', '…', '구글', '15조원', '들여', '美', '전역', '거점', '화'], 'label': '4'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b02-gNCKPEC3","executionInfo":{"status":"ok","timestamp":1626682284501,"user_tz":-540,"elapsed":17,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"c7fa64d8-029e-475f-ca3a-f1cea6ecca59"},"source":["text.build_vocab(train, min_freq=2)\n","print(len(text.vocab))\n","print(list(text.vocab.stoi)[:20])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["20843\n","['<unk>', '<pad>', '…', '에', '·', '종합', '서', '의', '로', '한', '2', '도', '명', '이', '대통령', '은', '3', '1', '美', '한국']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CoRYr80WPVJ_","executionInfo":{"status":"ok","timestamp":1626682362251,"user_tz":-540,"elapsed":426,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"a66cabdf-bcb0-4674-95a1-2b9e8fc2bd46"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device, torch.cuda.get_device_name(0))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tNkIbO2lPgwH"},"source":["BATCH_SIZE = 32\n","train_iter = BucketIterator(train, batch_size=BATCH_SIZE, sort_key=lambda x: len(x.text),\n","                            device=device, train=True, sort=True, sort_within_batch=True)\n","test_iter = Iterator(test, batch_size=BATCH_SIZE, \n","                     device=device, train=False, shuffle=False, sort=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i7r08ojjQVx6","executionInfo":{"status":"ok","timestamp":1626682296692,"user_tz":-540,"elapsed":11741,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"b9825dcf-e431-430f-caad-72b95eb1438d"},"source":["batch = next(iter(train_iter))\n","ex = batch.text\n","print(ex.shape)\n","ex[:5]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([32, 22])\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["tensor([[ 2133,    31,  9375,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1],\n","        [  427,  5780,  3192,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1],\n","        [   55, 15318,   190,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1],\n","        [   55,  5276,  5879,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1],\n","        [ 3367,   996,   192,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n","             1,     1]], device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"R_RiWBGziO2J"},"source":["# 모델링"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y_PVxaIULKtP","executionInfo":{"status":"ok","timestamp":1626955474840,"user_tz":-540,"elapsed":323,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"8f2b94a0-6187-41bd-cccb-be60b19ca42d"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device, torch.cuda.get_device_name(0))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["0231af189014405697587319e56f7ef3","5305a95715c842d8b9ae6e86537a96dd","f94d1d76b8e64f748ee30be815517d3e","3ab0ae8bcd2046e1bfbe3413d571ecb7","d7962aa08fc043b789f27e0d878c4ed7","32e8f47817d24ab8b189260e92870081","409a0c3ad75345a992ae170121dc7e88","06d7c317c647427893084c8108da30f6","78c361e1139042f8bc0d1726c5c35b92","bc97e8299d6941b79952ebfdeb0f0566","83e9d85a3155496392f57c7ab4ff1616","3bdc7d31815c4e10b8d23017c94f0522","372048e528244c13bf8ef0cae02c1e02","e7b0b60077844f27b741844587f7ca2f","4ddf56d982354e029b1ee428676e541b","b8e9c22b57d344c1af5b52a6ceaec811"]},"id":"OxwNS4jrLN0a","executionInfo":{"status":"ok","timestamp":1626955511293,"user_tz":-540,"elapsed":33224,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"8155659a-bb42-47b6-fd2c-a5d50a0daade"},"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=7)\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0231af189014405697587319e56f7ef3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78c361e1139042f8bc0d1726c5c35b92","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"zkXOtStFLRcH"},"source":["optimizer = optim.AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)\n","epochs = 10\n","total_steps = len(train_dataloader) * epochs\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aefJAqVQL5qn"},"source":["def flat_accuracy(preds, labels):\n","    \n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e6UZC6bML5M8"},"source":["def format_time(elapsed):\n","    elapsed_rounded = int(round((elapsed)))\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQrRuvgOOCMy"},"source":["import time\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J83l98SxLx-6","executionInfo":{"status":"ok","timestamp":1626961028431,"user_tz":-540,"elapsed":3093717,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"49c2df82-9820-4f4e-9f2d-9334e5f33d76"},"source":["model.zero_grad()\n","\n","for epoch_i in range(0, epochs):\n","\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    t0 = time.time()\n","\n","    total_loss = 0\n","\n","    model.train()\n","        \n","    for step, batch in enumerate(train_dataloader):\n","\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        b_input_ids, b_input_mask, b_labels = batch\n","             \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","\n","        loss = outputs[0]\n","        total_loss += loss.item()\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","\n","        optimizer.step()\n","        scheduler.step()\n","\n","        model.zero_grad()\n","\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["======== Epoch 1 / 10 ========\n","Training...\n","  Batch   500  of  1,427.    Elapsed: 0:01:47.\n","  Batch 1,000  of  1,427.    Elapsed: 0:03:36.\n","\n","  Average training loss: 0.32\n","  Training epcoh took: 0:05:09\n","======== Epoch 2 / 10 ========\n","Training...\n","  Batch   500  of  1,427.    Elapsed: 0:01:49.\n","  Batch 1,000  of  1,427.    Elapsed: 0:03:38.\n","\n","  Average training loss: 0.24\n","  Training epcoh took: 0:05:11\n","======== Epoch 3 / 10 ========\n","Training...\n","  Batch   500  of  1,427.    Elapsed: 0:01:49.\n","  Batch 1,000  of  1,427.    Elapsed: 0:03:38.\n","\n","  Average training loss: 0.18\n","  Training epcoh took: 0:05:11\n","======== Epoch 4 / 10 ========\n","Training...\n","  Batch   500  of  1,427.    Elapsed: 0:01:49.\n","  Batch 1,000  of  1,427.    Elapsed: 0:03:38.\n","\n","  Average training loss: 0.14\n","  Training epcoh took: 0:05:11\n","======== Epoch 5 / 10 ========\n","Training...\n","  Batch   500  of  1,427.    Elapsed: 0:01:49.\n","  Batch 1,000  of  1,427.    Elapsed: 0:03:37.\n","\n","  Average training loss: 0.11\n","  Training epcoh took: 0:05:10\n","======== Epoch 6 / 10 ========\n","Training...\n","  Batch   500  of  1,427.    Elapsed: 0:01:49.\n","  Batch 1,000  of  1,427.    Elapsed: 0:03:37.\n","\n","  Average training loss: 0.08\n","  Training epcoh took: 0:05:10\n","======== Epoch 7 / 10 ========\n","Training...\n","  Batch   500  of  1,427.    Elapsed: 0:01:48.\n","  Batch 1,000  of  1,427.    Elapsed: 0:03:37.\n","\n","  Average training loss: 0.06\n","  Training epcoh took: 0:05:09\n","======== Epoch 8 / 10 ========\n","Training...\n","  Batch   500  of  1,427.    Elapsed: 0:01:48.\n","  Batch 1,000  of  1,427.    Elapsed: 0:03:36.\n","\n","  Average training loss: 0.05\n","  Training epcoh took: 0:05:09\n","======== Epoch 9 / 10 ========\n","Training...\n","  Batch   500  of  1,427.    Elapsed: 0:01:48.\n","  Batch 1,000  of  1,427.    Elapsed: 0:03:36.\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:05:08\n","======== Epoch 10 / 10 ========\n","Training...\n","  Batch   500  of  1,427.    Elapsed: 0:01:48.\n","  Batch 1,000  of  1,427.    Elapsed: 0:03:35.\n","\n","  Average training loss: 0.03\n","  Training epcoh took: 0:05:07\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ML2x-TZTIVIh","executionInfo":{"status":"ok","timestamp":1626961044086,"user_tz":-540,"elapsed":15674,"user":{"displayName":"­장현정(자연과학대학 통계학과)","photoUrl":"","userId":"14016880519286059984"}},"outputId":"fcaf2141-2c74-472b-cf36-c025f11daa6b"},"source":["#시작 시간 설정\n","t0 = time.time()\n","\n","# 평가모드로 변경\n","model.eval()\n","\n","# 변수 초기화\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","test_labels = []\n","\n","# 데이터로더에서 배치만큼 반복하여 가져옴\n","for step, batch in enumerate(test_dataloader):\n","    # 경과 정보 표시\n","    if step % 100 == 0 and not step == 0:\n","        elapsed = format_time(time.time() - t0)\n","        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n","\n","    # 배치를 GPU에 넣음\n","    batch = tuple(t.to(device) for t in batch)\n","    \n","    # 배치에서 데이터 추출\n","    #b_input_ids, b_input_mask, b_labels = batch\n","    b_input_ids, b_input_mask = batch\n","    \n","    # 그래디언트 계산 안함\n","    with torch.no_grad():     \n","        # Forward 수행\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","    \n","    # 로스 구함\n","    logits = outputs[0]\n","\n","    # CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","    #label_ids = b_labels.to('cpu').numpy()\n","\n","    pred_flat = np.argmax(logits, axis=1).flatten()\n","    for label in pred_flat:\n","        test_labels.append(label)\n","\n","print(\"\")\n","#print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\"Test took: {:}\".format(format_time(time.time() - t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  Batch   100  of    286.    Elapsed: 0:00:06.\n","  Batch   200  of    286.    Elapsed: 0:00:11.\n","\n","Test took: 0:00:16\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TZUnNaPyJhKQ"},"source":["submission['topic_idx'] = test_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-wHh6_95PK-a"},"source":["submission.to_csv(PATH+'0722_BERT_epoch10.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r6vkwWjyPYOu"},"source":[""],"execution_count":null,"outputs":[]}]}